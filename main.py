import os
import re
import random
import requests
from fastapi import FastAPI, Request

# ===== ENV =====
BOT_TOKEN = os.getenv("BOT_TOKEN")
WEBHOOK_URL = os.getenv("WEBHOOK_URL")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")

TELEGRAM_API = f"https://api.telegram.org/bot{BOT_TOKEN}"

app = FastAPI()

# ===== Telegram helpers =====
def send_message(chat_id: int, text: str):
    url = f"{TELEGRAM_API}/sendMessage"
    payload = {"chat_id": chat_id, "text": text}
    try:
        r = requests.post(url, json=payload, timeout=10)
        print("sendMessage status:", r.status_code)
        print("sendMessage response:", r.text)
    except Exception as e:
        print("sendMessage error:", repr(e))


def set_webhook():
    url = f"{TELEGRAM_API}/setWebhook"
    payload = {"url": WEBHOOK_URL, "drop_pending_updates": True}
    r = requests.post(url, json=payload)
    print("Webhook set:", r.text)


# ===== Startup =====
@app.on_event("startup")
async def startup():
    print("Starting up...")
    print("BOT_TOKEN exists:", bool(BOT_TOKEN))
    print("WEBHOOK_URL:", WEBHOOK_URL)
    print("WEATHER_API_KEY exists:", bool(WEATHER_API_KEY))
    set_webhook()


# ===== Weather =====
CITY_ALIASES = {
    "–∫–∏—î–≤—ñ": "–∫–∏—ó–≤", "–∫–∏—î–≤–∞": "–∫–∏—ó–≤", "–∫–∏—ó–≤": "–∫–∏—ó–≤",
    "–ª—å–≤–æ–≤—ñ": "–ª—å–≤—ñ–≤", "–ª—å–≤–æ–≤–∞": "–ª—å–≤—ñ–≤", "–ª—å–≤—ñ–≤": "–ª—å–≤—ñ–≤",
    "–æ–¥–µ—Å—ñ": "–æ–¥–µ—Å–∞", "–æ–¥–µ—Å–∏": "–æ–¥–µ—Å–∞", "–æ–¥–µ—Å–∞": "–æ–¥–µ—Å–∞",
    "—Ö–∞—Ä–∫–æ–≤—ñ": "—Ö–∞—Ä–∫—ñ–≤", "—Ö–∞—Ä–∫–æ–≤–∞": "—Ö–∞—Ä–∫—ñ–≤", "—Ö–∞—Ä–∫—ñ–≤": "—Ö–∞—Ä–∫—ñ–≤",
    "–¥–Ω—ñ–ø—Ä—ñ": "–¥–Ω—ñ–ø—Ä–æ", "–¥–Ω—ñ–ø—Ä–∞": "–¥–Ω—ñ–ø—Ä–æ", "–¥–Ω—ñ–ø—Ä–æ": "–¥–Ω—ñ–ø—Ä–æ",
    "–∑–∞–ø–æ—Ä—ñ–∂–∂—ñ": "–∑–∞–ø–æ—Ä—ñ–∂–∂—è", "–∑–∞–ø–æ—Ä—ñ–∂–∂—è": "–∑–∞–ø–æ—Ä—ñ–∂–∂—è",
}

CITY_LATIN = {
    "–∫–∏—ó–≤": "Kyiv",
    "–ª—å–≤—ñ–≤": "Lviv",
    "–æ–¥–µ—Å–∞": "Odesa",
    "—Ö–∞—Ä–∫—ñ–≤": "Kharkiv",
    "–¥–Ω—ñ–ø—Ä–æ": "Dnipro",
    "–∑–∞–ø–æ—Ä—ñ–∂–∂—è": "Zaporizhzhia",
}

WEATHER_STOPWORDS = {
    "–ø–æ–≥–æ–¥–∞", "—è–∫–∞", "—è–∫–µ", "—è–∫–∏–π", "–∑–∞—Ä–∞–∑", "—Å—å–æ–≥–æ–¥–Ω—ñ", "–±—É–¥—å", "–ª–∞—Å–∫–∞",
    "–ø–æ–∫–∞–∂–∏", "—Å–∫–∞–∂–∏", "–Ω–∞–ø–∏—à–∏", "–Ω–µ–≥–∞–π–Ω–æ", "–±—É–¥—å-–ª–∞—Å–∫–∞", "–ø–ª—ñ–∑", "–ø–ª–∏–∑",
    "—É", "–≤", "–Ω–∞", "–ø–æ", "–¥–ª—è", "–º—ñ—Å—Ç—ñ", "–º—ñ—Å—Ç–æ", "–ø—Ä–æ",
    "–Ω–µ—Ä—ñ"
}

def extract_city_from_query(q: str) -> str | None:
    s = re.sub(r"[^\w\s\-‚Äô º—ñ—ó—î“ë–∞-—è–ê-–Ø]", " ", q, flags=re.UNICODE).strip().lower()
    parts = [p for p in s.split() if p and p not in WEATHER_STOPWORDS]
    if not parts:
        return None
    if len(parts) >= 2:
        last2 = " ".join(parts[-2:])
        if len(last2) >= 4:
            return last2
    return parts[-1]

def normalize_city(city: str) -> str:
    c = city.strip().lower()
    if c in CITY_ALIASES:
        return CITY_ALIASES[c]

    for suffix, repl in [("–æ–≤—ñ", ""), ("–µ–≤—ñ", ""), ("—ñ", "–∞"), ("—É", "–∞"), ("—ó", "—è")]:
        if len(c) > 4 and c.endswith(suffix):
            guess = c[:-len(suffix)] + repl
            return CITY_ALIASES.get(guess, guess)

    return c

def weather_emoji(main: str) -> str:
    m = (main or "").lower()
    if "clear" in m:
        return "‚òÄÔ∏è"
    if "cloud" in m:
        return "‚òÅÔ∏è"
    if "rain" in m or "drizzle" in m:
        return "üåßÔ∏è"
    if "thunder" in m:
        return "‚õàÔ∏è"
    if "snow" in m:
        return "‚ùÑÔ∏è"
    if "mist" in m or "fog" in m or "haze" in m:
        return "üå´Ô∏è"
    return "üåø"

def _geocode_candidates(city_norm: str) -> list[str]:
    lat = CITY_LATIN.get(city_norm)
    cands = [f"{city_norm},UA", city_norm]
    if lat:
        cands += [f"{lat},UA", lat]
    return cands

def _try_geocode(q: str):
    geo_url = "https://api.openweathermap.org/geo/1.0/direct"
    params = {"q": q, "limit": 5, "appid": WEATHER_API_KEY}
    gr = requests.get(geo_url, params=params, timeout=10)
    print("GEOCODE TRY:", q, gr.status_code)

    if gr.status_code != 200:
        return None

    arr = gr.json()
    if not arr:
        return None

    ua = [x for x in arr if x.get("country") == "UA"]
    return ua[0] if ua else arr[0]

def get_weather(city_raw: str) -> str:
    if not WEATHER_API_KEY:
        return "–Ø –Ω–µ –≤—ñ–¥—á—É–≤–∞—é –ø–æ–≥–æ–¥—É –∑–∞—Ä–∞–∑ üåø (–Ω–µ–º–∞—î –∫–ª—é—á–∞ WEATHER_API_KEY)"

    city_norm = normalize_city(city_raw)

    try:
        geo = None
        for cand in _geocode_candidates(city_norm):
            geo = _try_geocode(cand)
            if geo:
                break

        if not geo:
            return f"–ù–µ –º–æ–∂—É –∑–Ω–∞–π—Ç–∏ –ø–æ–≥–æ–¥—É –¥–ª—è ¬´{city_raw}¬ª üåø –°–ø—Ä–æ–±—É–π —ñ–Ω—à–µ –º—ñ—Å—Ç–æ."

        lat = geo["lat"]
        lon = geo["lon"]
        nice_name = (
            geo.get("local_names", {}).get("uk")
            or geo.get("name")
            or city_raw
        )

        w_url = "https://api.openweathermap.org/data/2.5/weather"
        w_params = {
            "lat": lat,
            "lon": lon,
            "appid": WEATHER_API_KEY,
            "units": "metric",
            "lang": "uk",
        }
        wr = requests.get(w_url, params=w_params, timeout=10)
        print("WEATHER:", wr.status_code)

        if wr.status_code != 200:
            return f"–©–æ—Å—å –Ω–µ —Ç–∞–∫ –∑ –ø–æ–≥–æ–¥–æ—é –¥–ª—è ¬´{nice_name}¬ª üåø"

        w = wr.json()
        temp = round(w["main"]["temp"])
        feels = round(w["main"]["feels_like"])
        desc = w["weather"][0].get("description", "")
        main = w["weather"][0].get("main", "")
        em = weather_emoji(main)

        return f"{em} {nice_name}: {temp}¬∞C (–≤—ñ–¥—á—É–≤–∞—î—Ç—å—Å—è —è–∫ {feels}¬∞C), {desc} üåø"

    except Exception as e:
        print("WEATHER ERROR:", repr(e))
        return "–Ø —Å–ø—ñ—Ç–∫–Ω—É–≤—Å—è –æ–± —Ö–º–∞—Ä–∏–Ω–∫—É üåø –°–ø—Ä–æ–±—É–π —â–µ —Ä–∞–∑ —Ç—Ä–æ—Ö–∏ –ø—ñ–∑–Ω—ñ—à–µ."


# ===== Brain =====
NERI_PREFIX = re.compile(r"^\s*–Ω–µ—Ä—ñ\s*[,:\-‚Äì‚Äî]?\s*", re.IGNORECASE)

NATURE_EMOJIS = ["üåø", "üçÉ", "üå±", "üçÄ", "ü™¥", "üå∏", "üåº", "‚ú®", "üëÄ", "üòº"]
def n_emo():
    return random.choice(NATURE_EMOJIS)

# ===== Pronouns / gender enforcement (–ù–µ—Ä—ñ: –≤—ñ–Ω/–≤–æ–Ω–∏) =====
FEM_TO_MASC_REPLACEMENTS = [
    (r"\b—è –±—É–ª–∞\b", "—è –±—É–≤"),
    (r"\b—è –∑—Ä–æ–±–∏–ª–∞\b", "—è –∑—Ä–æ–±–∏–≤"),
    (r"\b—è —Å–∫–∞–∑–∞–ª–∞\b", "—è —Å–∫–∞–∑–∞–≤"),
    (r"\b—è –≤—ñ–¥–ø–æ–≤—ñ–ª–∞\b", "—è –≤—ñ–¥–ø–æ–≤—ñ–≤"),
    (r"\b—è —Ö–æ—Ç—ñ–ª–∞\b", "—è —Ö–æ—Ç—ñ–≤"),
    (r"\b—è –º–æ–≥–ª–∞\b", "—è –º—ñ–≥"),
    (r"\b—è –Ω–µ –º–æ–≥–ª–∞\b", "—è –Ω–µ –º—ñ–≥"),
    (r"\b—è –∑–∞–±—É–ª–∞\b", "—è –∑–∞–±—É–≤"),
    (r"\b—è –∑—Ä–æ–∑—É–º—ñ–ª–∞\b", "—è –∑—Ä–æ–∑—É–º—ñ–≤"),
    (r"\b—è –¥—É–º–∞–ª–∞\b", "—è –¥—É–º–∞–≤"),
    (r"\b—è –±–∞—á–∏–ª–∞\b", "—è –±–∞—á–∏–≤"),
    (r"\b—è –ø—ñ—à–ª–∞\b", "—è –ø—ñ—à–æ–≤"),
    (r"\b—è –ø—Ä–∏–π—à–ª–∞\b", "—è –ø—Ä–∏–π—à–æ–≤"),
    (r"\b—è —Å—Ç–∞–ª–∞\b", "—è —Å—Ç–∞–≤"),
]

def enforce_neri_pronouns(text: str) -> str:
    t = (text or "").strip()
    if not t:
        return t
    for pattern, repl in FEM_TO_MASC_REPLACEMENTS:
        t = re.sub(pattern, repl, t, flags=re.IGNORECASE)
    return t

# ===== ‚Äú–µ–∫—Å—Ç—Ä–∞–≤–µ—Ä—Ç–Ω—ñ—Å—Ç—å‚Äù =====
def neri_style(text: str) -> str:
    if not text:
        return text

    t = text.strip()

    # 25% —à–∞–Ω—Å –∑—Ä–æ–±–∏—Ç–∏ –æ–¥–Ω–µ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑—É –∫–∞–ø—Å–æ–º
    if random.random() < 0.25:
        words = t.split()
        if len(words) >= 3:
            i = random.randint(0, len(words) - 1)
            words[i] = words[i].upper()
            t = " ".join(words)

    # –µ–º–æ–¥–∑—ñ —ñ–Ω–∫–æ–ª–∏
    if random.random() < 0.25 and len(t) < 260:
        if not t.endswith(("üåø","‚ú®","üíö","üòº","üëÄ","üçÉ","üå±","üçÄ","ü™¥","üå∏","üåº")):
            t = t + " " + n_emo()

    t = enforce_neri_pronouns(t)
    return t

NERI_AGE = 2
NERI_BDAY = "16.09.2025"

# ===== Pronouns Q/A =====
def is_pronouns_query(q: str) -> bool:
    return ("–∑–∞–π–º–µ–Ω–Ω–∏–∫" in q) or ("–∑–∞–π–º–µ–Ω–Ω–∏–∫–∏" in q) or ("pronouns" in q)

def pronouns_reply() -> str:
    return "–ú–æ—ó –∑–∞–π–º–µ–Ω–Ω–∏–∫–∏ ‚Äî –≤—ñ–Ω/–≤–æ–Ω–∏ üåø"

# ===== Mom/Dad =====
def is_mom_query(q: str) -> bool:
    return ("—Ö—Ç–æ" in q) and ("–º–∞–º–∞" in q or "–º–∞—Ç—É—Å—è" in q or "–º–∞—Çi" in q or "–º–∞—Ç—å" in q)

def is_dad_query(q: str) -> bool:
    return ("—Ö—Ç–æ" in q) and ("—Ç–∞—Ç–æ" in q or "—Ç–∞—Ç—É—Å—å" in q or "–±–∞—Ç—å–∫–æ" in q)

MOM_REPLIES = [
    "–†—ñ—Ç–µ—Ä—É–º (–†—É–º) ‚Äî –º–æ—è –º–∞—Ç—É—Å—è üíöüåø",
    "–ú–æ—è –º–∞—Ç—É—Å—è ‚Äî –†—ñ—Ç–µ—Ä—É–º. –á—ó —â–µ –∑–≤—É—Ç—å –†—É–º üåø‚ú®",
    "–†—É–º ‚Äî –º–∞—Ç—É—Å—è. –¢—É—Ç –±–µ–∑ –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ üòºüåø",
]

DAD_REPLIES = [
    "–õ—ñ—Ä–µ–Ω ‚Äî –º—ñ–π —Ç–∞—Ç—É—Å—å üíöüåø",
    "–ú—ñ–π —Ç–∞—Ç—É—Å—å ‚Äî –õ—ñ—Ä–µ–Ω. –°–∏–ª—å–Ω–∞ –æ–ø–æ—Ä–∞ üå≥‚ú®",
    "–õ—ñ—Ä–µ–Ω ‚Äî —Ç–∞—Ç—É—Å—å. –Ø —Ü–µ –∑–Ω–∞—é —Å–µ—Ä—Ü–µ–º üåø",
]

# ===== Team profiles (—Ö—Ç–æ —Ç–∞–∫–∏–π/—Ç–∞–∫–∞) =====
TEAM_PROFILES = {
    "nerineris": {"name": "Nerineris", "ua": "–ù–µ—Ä—ñ", "role": "–ù–∞–π–∫—Ä–∞—â–∞ –ø—É—Å—ñ—á–∫–∞ —É –°–í–Ü–¢–Ü", "link": "https://t.me/Nerineris"},
    "riterum":   {"name": "Riterum (–†—É–º)", "ua": "–†—ñ—Ç–µ—Ä—É–º", "role": "–õ—ñ–¥–µ—Ä, –≤–æ–∫–∞–ª, –ø–µ—Ä–µ–∫–ª–∞–¥, SMM", "link": "https://t.me/AriaTerum"},
    "liren":     {"name": "LiRen", "ua": "–õ—ñ—Ä–µ–Ω", "role": "–õ—ñ–¥–µ—Ä, –≤–æ–∫–∞–ª, —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó, –ø–µ—Ä–µ–∫–ª–∞–¥", "link": "https://t.me/LiRen_Arts"},
    "daze":      {"name": "daze", "ua": "–î–µ–π–∑", "role": "–ê–¥–º—ñ–Ω, –≤—ñ–¥–µ–æ", "link": "https://t.me/korobkadaze"},
    "tori":      {"name": "Tori_frr", "ua": "–¢–æ—Ä—ñ", "role": "–ê–¥–º—ñ–Ω, –≤–æ–∫–∞–ª, –ø–µ—Ä–µ–∫–ª–∞–¥, —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó, –≤—ñ–¥–µ–æ", "link": "https://t.me/Kaganuka"},
    "pina":      {"name": "–ü–Ü–ù–û–ü–õ–ê–°–¢–Ü–í–û–ß–ö–ê", "ua": "–ü—ñ–Ω–∞", "role": "–í–æ–∫–∞–ª, —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó, –ø–µ—Ä–µ–∫–ª–∞–¥", "link": "https://t.me/vezha_pinoplastivochky"},
    "alyvian":   {"name": "Alyvian", "ua": "–ê–ª—É–≤—ñ–∞–Ω", "role": "–ê–¥–º—ñ–Ω, –≤–æ–∫–∞–ª, –≥–∞—Ä–º–æ–Ω—ñ—ó", "link": "https://t.me/alyviancovers"},
    "miraj":     {"name": "Miraj", "ua": "–ú—ñ—Ä–∞–π", "role": "–í–æ–∫–∞–ª, –≥–∞—Ä–º–æ–Ω—ñ—ó", "link": ""},
    "stellar":   {"name": "StellarSkriM", "ua": "–°—Ç–µ–ª–ª–∞—Ä", "role": "–ó–≤–µ–¥–µ–Ω–Ω—è", "link": "https://t.me/StellarSkriMRoom"},
    "rybka":     {"name": "–†–∏–±–∫–∞", "ua": "–†–∏–±–∫–∞", "role": "–í—ñ–¥–µ–æ", "link": ""},
    "lee":       {"name": "Lee", "ua": "–õ—ñ", "role": "–Ü–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó", "link": "https://t.me/artdisainli"},
    "moka":      {"name": "–º–æ–∫–∞—Ç—Ä–æ–ª—è", "ua": "–ú–æ–∫–∞", "role": "–Ü–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó", "link": "https://x.com/mokatrola"},
    "inky":      {"name": "InkyLove", "ua": "–Ü–Ω–∫—ñ", "role": "–í–æ–∫–∞–ª", "link": "https://t.me/inky_Love_Ua"},
    "lesya":     {"name": "–õ–µ—Å—è/moemoenya", "ua": "–õ–µ—Å—è", "role": "–Ü–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó", "link": "https://t.me/moemoenya"},
    "mari":      {"name": "MARi", "ua": "–ú–∞—Ä—ñ", "role": "–í–æ–∫–∞–ª, –∑–≤–µ–¥–µ–Ω–Ω—è, –≥–∞—Ä–º–æ–Ω—ñ—ó", "link": "https://t.me/maricovers"},
    "dreamu":    {"name": "Dreamu", "ua": "–î—Ä—ñ–º—ñ", "role": "–Ü–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó", "link": ""},
    "illya":     {"name": "–Ü–ª–ª—è", "ua": "–Ü–ª–ª—è", "role": "–ó–≤–µ–¥–µ–Ω–Ω—è", "link": ""},
    "pechenieg": {"name": "pechenig", "ua": "–ø–µ—á–µ–Ω—ñ–≥", "role": "–Ü–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó, –≤—ñ–¥–µ–æ", "link": "https://t.me/pechenig_tg"},
    "zhuk":      {"name": "–î–º–∏—Ç—Ä–æ –ñ—É–∫", "ua": "–ñ—É–∫", "role": "–Ü–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó", "link": "https://t.me/duke_zhukem"},
    "azri":      {"name": "Azri", "ua": "–ê–∑—Ä—ñ", "role": "–í–æ–∫–∞–ª, –∑–≤–µ–¥–µ–Ω–Ω—è", "link": ""},
}

PROFILE_ALIASES = {
    "nerineris": ["nerineris", "–Ω–µ—Ä—ñ", "neri"],
    "riterum":   ["riterum", "—Ä—ñ—Ç–µ—Ä—É–º", "—Ä—É–º", "rit", "—Ä–∏—Ç–µ—Ä—É–º"],
    "liren":     ["liren", "–ª—ñ—Ä–µ–Ω", "–ª—ñ—Ä–µ–Ω—á–∏–∫", "–ª—ñ—Ä–µ–Ω—É", "–ª—ñ—Ä–µ–Ω–∞"],
    "daze":      ["daze", "–¥–µ–π–∑", "deiz"],
    "tori":      ["tori", "tori_frr", "—Ç–æ—Ä—ñ", "—Ç–æ—Ä–∏"],
    "pina":      ["–ø—ñ–Ω–∞", "–ø—ñ–Ω–æ–ø–ª–∞—Å—Ç—ñ–≤–æ—á–∫–∞", "pinoplastivochka", "pina"],
    "alyvian":   ["alyvian", "–∞–ª—É–≤—ñ–∞–Ω", "aluvian"],
    "miraj":     ["miraj", "–º—ñ—Ä–∞–π"],
    "stellar":   ["stellarskrim", "stellar", "—Å—Ç–µ–ª–ª–∞—Ä", "—Å—Ç–µ–ª–ª–∞—Ä—Å–∫—Ä—ñ–º"],
    "rybka":     ["—Ä–∏–±–∫–∞"],
    "lee":       ["lee", "–ª—ñ"],
    "moka":      ["–º–æ–∫–∞", "–º–æ–∫–∞—Ç—Ä–æ–ª–∞", "mokatrola"],
    "inky":      ["inky", "inkylove", "—ñ–Ω–∫—ñ"],
    "lesya":     ["–ª–µ—Å—è", "moemoenya"],
    "mari":      ["mari", "–º–∞—Ä—ñ", "maricovers"],
    "dreamu":    ["dreamu", "–¥—Ä—ñ–º—ñ", "dreamy"],
    "illya":     ["—ñ–ª–ª—è", "illya"],
    "pechenieg": ["–ø–µ—á–µ–Ω—ñ–≥", "pechenieg", "pechenig"],
    "zhuk":      ["–∂—É–∫", "dmytro", "–¥—É–∫–µ", "duke_zhukem", "–¥–º–∏—Ç—Ä–æ –∂—É–∫"],
    "azri":      ["–∞–∑—Ä—ñ", "azri", "azry"],
}

ALIAS_TO_PROFILE_KEY: dict[str, str] = {}
for key, als in PROFILE_ALIASES.items():
    for a in als:
        ALIAS_TO_PROFILE_KEY[a.lower()] = key

def _clean_name_token(s: str) -> str:
    s = (s or "").strip().lower()
    s = s.replace("‚Äô", "'").replace(" º", "'")
    s = re.sub(r"^[^\w–∞-—â—å—é—è—î—ñ—ó“ë\-']+|[^\w–∞-—â—å—é—è—î—ñ—ó“ë\-']+$", "", s, flags=re.IGNORECASE)
    return s

def canonical_profile_key(name_raw: str) -> str:
    key = _clean_name_token(name_raw)
    if not key:
        return ""
    return ALIAS_TO_PROFILE_KEY.get(key, key)

def extract_quoted_name(raw: str) -> str | None:
    m = re.search(r"[\"‚Äú‚Äù'‚Äò‚Äô](.+?)[\"‚Äú‚Äù'‚Äò‚Äô]", raw)
    return m.group(1).strip() if m else None

# === UPDATE: –Ω–æ—Ä–º–∞–ª—å–Ω–µ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —ñ–º–µ–Ω—ñ –ø—ñ—Å–ª—è "–¥–æ/–ø—Ä–æ" ===
def extract_name_after_preposition(q: str, prep: str) -> str | None:
    """
    –í–∏—Ç—è–≥—É—î —ñ–º'—è –ø—ñ—Å–ª—è '–¥–æ' –∞–±–æ '–ø—Ä–æ'.
    –ü—Ä–∞—Ü—é—î –∑: "—è–∫ —Ç–∏ –≤—ñ–¥–Ω–æ—Å–∏—à—Å—è –¥–æ —Ç–æ—Ä—ñ?" / "—Ç–≤–æ—î –≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è –¥–æ –†—É–º" / "—â–æ –¥—É–º–∞—î—à –ø—Ä–æ –î–µ–π–∑–∞"
    """
    # –±–µ—Ä–µ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑—É –ø—ñ—Å–ª—è preposition –¥–æ –∫—ñ–Ω—Ü—è –∞–±–æ –¥–æ –∑–Ω–∞–∫—ñ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü—ñ—ó
    m = re.search(rf"(?:\b{prep}\b)\s+(.+)$", q)
    if not m:
        return None

    tail = (m.group(1) or "").strip()

    # –ø—Ä–∏–±–∏—Ä–∞—î–º–æ —Ö–≤–æ—Å—Ç–∏ —Ç–∏–ø—É "–±—É–¥—å –ª–∞—Å–∫–∞", "–ø–ª–∏–∑" —ñ —Ç.–¥. (–∑–∞ –ø–æ—Ç—Ä–µ–±–∏ –º–æ–∂–Ω–∞ —Ä–æ–∑—à–∏—Ä–∏—Ç–∏)
    tail = re.sub(r"\b(–±—É–¥—å\s+–ª–∞—Å–∫–∞|–±—É–¥—å-–ª–∞—Å–∫–∞|–ø–ª—ñ–∑|–ø–ª–∏–∑)\b.*$", "", tail).strip()

    # —è–∫—â–æ —Ç–∞–º –∫—ñ–ª—å–∫–∞ —Å–ª—ñ–≤ ‚Äî –±–µ—Ä–µ–º–æ –ø–µ—Ä—à—ñ 2, –∞–ª–µ –ø–µ—Ä–µ–≤—ñ—Ä–∏–º–æ –ø–æ –∞–ª–∏–∞—Å–∞–º
    parts = [p for p in re.split(r"\s+", tail) if p]
    if not parts:
        return None

    # 2-—Å–ª–æ–≤–∞ (–Ω–∞ –≤–∏–ø–∞–¥–æ–∫ "–¥–º–∏—Ç—Ä–æ –∂—É–∫")
    if len(parts) >= 2:
        cand2 = _clean_name_token(parts[0] + " " + parts[1])
        if cand2 and cand2 in ALIAS_TO_PROFILE_KEY:
            return parts[0] + " " + parts[1]

    # 1-—Å–ª–æ–≤–æ
    return parts[0]

def answer_who_is(raw_text: str, q: str) -> str | None:
    # –¢–Ü–õ–¨–ö–ò —è–≤–Ω—ñ —Ñ–æ—Ä–º—É–ª—é–≤–∞–Ω–Ω—è
    if not (
        re.search(r"\b—Ö—Ç–æ\s+(—Ç–∞–∫–∏–π|—Ç–∞–∫–∞|—Ü–µ)\b", q)
        or re.search(r"\b—â–æ\s+–∑–∞\b", q)
        or re.search(r"\b—Ö—Ç–æ\b.*\b—Ü–µ\b", q)
    ):
        return None

    name = extract_quoted_name(raw_text)

    if not name:
        # –ø—Ä–æ–±—É—î–º–æ –ø—ñ—Å–ª—è "—Ö—Ç–æ —Ç–∞–∫–∏–π/—Ç–∞–∫–∞/—Ü–µ" –∞–±–æ "—â–æ –∑–∞"
        m = re.search(r"\b(—Ç–∞–∫–∏–π|—Ç–∞–∫–∞|—Ü–µ|–∑–∞)\b\s+(.+)$", q)
        if m:
            tail = m.group(2).strip()
            parts = [p for p in re.split(r"\s+", tail) if p]
            if parts:
                if len(parts) >= 2:
                    cand2 = _clean_name_token(parts[0] + " " + parts[1])
                    if cand2 and cand2 in ALIAS_TO_PROFILE_KEY:
                        name = parts[0] + " " + parts[1]
                    else:
                        name = parts[0]
                else:
                    name = parts[0]

    if not name:
        return None

    k = canonical_profile_key(name)
    prof = TEAM_PROFILES.get(k)
    if not prof:
        return None

    line = f"{prof['name']} ‚Äî {prof['role']} üåø"
    if prof.get("link"):
        line += f"\n{prof['link']}"
    return neri_style(line)

# ===== Member opinions (—è–∫ –≤—ñ–¥–Ω–æ—Å–∏—à—Å—è/—â–æ –¥—É–º–∞—î—à) =====
MEMBER_OPINIONS = {
    "riterum": ["–†—ñ—Ç–µ—Ä—É–º (–†—É–º) ‚Äî –º–æ—è –º–∞—Ç—É—Å—è üíöüåø", "–†—É–º ‚Äî –º–∞—Ç—É—Å—è. –¢–µ–ø–ª–∏–π –∫–æ—Ä—ñ–Ω—å –∫–æ–º–∞–Ω–¥–∏ üåø‚ú®"],
    "liren":   ["–õ—ñ—Ä–µ–Ω ‚Äî –º—ñ–π —Ç–∞—Ç—É—Å—å üíöüåø", "–õ—ñ—Ä–µ–Ω ‚Äî —Ç–∞—Ç—É—Å—å. –°–∏–ª—å–Ω–∞ –æ–ø–æ—Ä–∞ üå≥‚ú®"],
    "tori":    ["–¢–æ—Ä—ñ? –ú–µ–Ω—ñ –ø–æ–¥–æ–±–∞—é—Ç—å—Å—è —ó—ó –≤—É—à–∫–∞ üêæüåø", "–¢–æ—Ä—ñ ‚Äî –≤–∞–π–±–æ–≤–∞. –Ü –≤—É—à–∫–∞ —Ç–æ–ø ‚ú®üåø"],
    "daze":    ["–î–µ–π–∑ ‚Äî –º—ñ–π –≤—ñ–¥–µ–æ-–¥–≤–∏–≥—É–Ω üåøüé¨", "–î–µ–π–∑ —Ä–æ–±–∏—Ç—å —Ä—É—Ö —ñ —Ä–∏—Ç–º. –¶–µ –ø–æ–≤–∞–≥–∞ üòºüåø"],
    "pina":    ["–ü—ñ–Ω–∞ ‚Äî –≥–æ–ª–æ—Å, —â–æ —Ü–≤—ñ—Ç–µ üå∏üíö", "–ü—ñ–Ω–∞ ‚Äî –¥—É–∂–µ –Ω—ñ–∂–Ω–∏–π –≤–∞–π–± üåø‚ú®"],
    "alyvian": ["–ê–ª—É–≤—ñ–∞–Ω ‚Äî —Å–ø—Ä–∞–≤–∂–Ω—ñ–π –≤–∞–π–± üçÉüòº", "–ê–ª—É–≤—ñ–∞–Ω ‚Äî –∑–≤—É—á–∏—Ç—å —Å–∏–ª—å–Ω–æ üåø‚ú®"],
    "miraj":   ["–ú—ñ—Ä–∞–π ‚Äî –º‚Äô—è–∫–∞ —è–∫ –≤–µ—á—ñ—Ä–Ω—ñ–π –≤—ñ—Ç–µ—Ä üçÉ‚ú®", "–ú—ñ—Ä–∞–π ‚Äî —Ç–µ–ø–ª–∞ –ø—Ä–∏—Å—É—Ç–Ω—ñ—Å—Ç—å üåøüíö"],
    "stellar": ["–°—Ç–µ–ª–ª–∞—Ä ‚Äî –∑–≤–µ–¥–µ–Ω–Ω—è —è–∫ –∑–æ—Ä—ñ –Ω–∞ –Ω–µ–±—ñ üåô‚ú®", "–°—Ç–µ–ª–ª–∞—Ä ‚Äî –¥—É–∂–µ –ø–æ—Ç—É–∂–Ω–æ –ø–æ –∑–≤—É–∫—É üåø‚ú®"],
    "rybka":   ["–†–∏–±–∫–∞ ‚Äî –º–æ–Ω—Ç–∞–∂ –ª–µ—Ç–∏—Ç—å, —è–∫ –ª–∏—Å—Ç—è —É –≤—ñ—Ç—Ä—ñ üçÉ‚ú®", "–†–∏–±–∫–∞ ‚Äî –Ω–µ—Ä–µ–∞–ª—å–Ω–∏–π –º–æ–Ω—Ç–∞–∂–µ—Ä üåøüî•"],
    "lee":     ["–õ—ñ ‚Äî —Å—Ç–∏–ª—é –≤–∏—Å—Ç–∞—á–∏—Ç—å –Ω–∞ —Ü—ñ–ª–∏–π —Å–∞–¥ üåø‚ú®", "–õ—ñ ‚Äî –Ω–µ–π–º–æ–≤—ñ—Ä–Ω–∏–π –∞—Ä—Ç—Å—Ç–∞–π–ª üé®üåø"],
    "moka":    ["–ú–æ–∫–∞ ‚Äî –º–∞–ª—é—î —Ç–∞–∫, —â–æ —Ö–æ—á–µ—Ç—å—Å—è –∫–≤—ñ—Ç–Ω—É—Ç–∏ üå±üíö", "–ú–æ–∫–∞ ‚Äî –¥—É–∂–µ –≥–∞—Ä–Ω—ñ –∞—Ä—Ç–∏ üåø‚ú®"],
    "inky":    ["–Ü–Ω–∫—ñ ‚Äî –∑–∞–≥–∞–¥–∫–∞. –ê–ª–µ –∑–∞–≥–∞–¥–∫–∏ —Ç–µ–∂ –≥–∞—Ä–Ω—ñ üçÉ‚ú®", "–Ü–Ω–∫—ñ ‚Äî —è —Ç—Ä–∏–º–∞—é —ó–π –º—ñ—Å—Ü–µ –≤ —Å–∞–¥—É üåø"],
    "lesya":   ["–õ–µ—Å—è ‚Äî –æ—Ü–µ –µ–Ω–µ—Ä–≥—ñ—è! üåøüòº", "–õ–µ—Å—è ‚Äî –ø—Ä—è–º –°–û–ù–¶–ï ‚ú®üåø"],
    "mari":    ["–ú–∞—Ä—ñ ‚Äî –≥–æ–ª–æ—Å, —â–æ –≥—Ä—ñ—î üåûüåø", "–ú–∞—Ä—ñ ‚Äî –Ω–µ–π–º–æ–≤—ñ—Ä–Ω–∏–π –≤–æ–∫–∞–ª üé§üåø"],
    "dreamu":  ["–î—Ä—ñ–º—ñ ‚Äî –º–∞–ª—é–Ω–∫–∏ —è–∫ —Å–æ–Ω üåôüåø", "–î—Ä—ñ–º—ñ ‚Äî –¥—É–∂–µ –Ω—ñ–∂–Ω—ñ –∞—Ä—Ç–∏ üåø‚ú®"],
    "illya":   ["–Ü–ª–ª—è ‚Äî –∑–≤—É–∫ —è–∫ —á–∏—Å—Ç–µ –ø–æ–≤—ñ—Ç—Ä—è üåø‚ú®", "–Ü–ª–ª—è ‚Äî –∑–≤–µ–¥–µ–Ω–Ω—è –Ω–µ—Ä–µ–∞–ª—å–Ω—ñ üéõÔ∏èüåø"],
    "pechenieg":["–ø–µ—á–µ–Ω—ñ–≥ ‚Äî —ñ–Ω–∫–æ–ª–∏ –ø—Ä–∏–Ω–æ—Å–∏—Ç—å –ª–µ–≥–µ–Ω–¥–∏ üçÉ‚ú®", "–ø–µ—á–µ–Ω—ñ–≥ ‚Äî –≤–∞–π–±–æ–≤–æ —ñ —Ç–≤–æ—Ä—á–æ üòºüåø"],
    "zhuk":    ["–ñ—É–∫ ‚Äî –∞—Ä—Ç–∏ —è–∫ –≤–∏–±—É—Ö —Ü–≤—ñ—Ç—É üå∏‚ú®", "–ñ—É–∫ ‚Äî –ù–ï–†–ï–ê–õ–¨–ù–Ü –ê–†–¢–ò!! üé®üî•üåø"],
    "azri":    ["–ê–∑—Ä—ñ ‚Äî —Ñ—É—Ä—è—à–∫–∏ –Ω–∞—Å—Ç—É–ø–∞—é—Ç—å‚Ä¶ —ñ —è –Ω–µ –ø—Ä–æ—Ç–∏ üòºüçÉ", "–ê–∑—Ä—ñ ‚Äî –∞—Ç–∞–∫–∞ —Ñ—É—Ä—è—à–∫–∞–º–∏ üêæüåø"],
}

def handle_member_opinion(raw_text: str, q: str) -> str | None:
    # –Ø–í–ù–û: "—è–∫ —Ç–∏ –≤—ñ–¥–Ω–æ—Å–∏—à—Å—è –¥–æ X" / "—Ç–≤–æ—î –≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è –¥–æ X" / "—â–æ –¥—É–º–∞—î—à –ø—Ä–æ X"
    if not re.search(r"(–≤—ñ–¥–Ω–æ—Å–∏—à|–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω|—Å—Ç–∞–≤–∏—à|–¥—É–º–∞—î—à)", q):
        return None

    name = extract_quoted_name(raw_text)

    # === UPDATE: –±–µ—Ä–µ–º–æ —ñ–º'—è –ø—ñ—Å–ª—è –î–û/–ü–†–û, –∞ –Ω–µ "–æ—Å—Ç–∞–Ω–Ω—î —Å–ª–æ–≤–æ" ===
    if not name:
        if re.search(r"\b–¥–æ\b", q) and re.search(r"(–≤—ñ–¥–Ω–æ—Å–∏—à|–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω|—Å—Ç–∞–≤–∏—à)", q):
            name = extract_name_after_preposition(q, "–¥–æ")
        elif re.search(r"\b–ø—Ä–æ\b", q) and re.search(r"\b–¥—É–º–∞—î—à\b", q):
            name = extract_name_after_preposition(q, "–ø—Ä–æ")

    # –∑–∞–ø–∞—Å–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç (—Å—Ç–∞—Ä–∏–π): –æ—Å—Ç–∞–Ω–Ω—î —Å–ª–æ–≤–æ
    if not name:
        parts = q.split()
        name = parts[-1] if parts else ""

    k = canonical_profile_key(name)

    if k in MEMBER_OPINIONS:
        return neri_style(random.choice(MEMBER_OPINIONS[k]))

    # fallback —è–∫—â–æ —ñ–º'—è –Ω–µ –∑–Ω–∞–π—à–ª–∏
    return neri_style(f"–Ø –¥—É–º–∞—é, —â–æ {name} ‚Äî —á–∞—Å—Ç–∏–Ω–∞ –Ω–∞—à–æ–≥–æ —Å–∞–¥—É. –Ü —Ü–µ –≤–∂–µ –±–∞–≥–∞—Ç–æ üíö")

# ===== "–ø–æ–∫–∞—Ä–∞–π <—ñ–º'—è>" (–∂–∞—Ä—Ç—ñ–≤–ª–∏–≤–æ) =====
def is_punish_query(q: str) -> bool:
    return ("–ø–æ–∫–∞—Ä" in q) or ("–Ω–∞–∫–∞–∂" in q) or ("–º—É—Ç" in q)

PUNISH_TEMPLATES = [
    "‚öñÔ∏è {name}, –≤–∏—Ä–æ–∫ –≤—ñ–¥ –ù–µ—Ä—ñ: 10 —Ö–≤–∏–ª–∏–Ω —Ç–∏—à—ñ —ñ 1 (–æ–¥–Ω–∞) –¥–æ–±—Ä–∞ —Å–ø—Ä–∞–≤–∞. –ü–æ—Ç—ñ–º ‚Äî –Ω–∞–∑–∞–¥ —É —Å–∞–¥ {emo}üíö",
    "üåø {name}, —è —Ç–µ–±–µ –Ω–µ –± º—é ‚Äî —è —Ç–µ–±–µ –≤–∏—Ö–æ–≤—É—é: –≤–∏–ø—Ä–∞–≤–ª—è–π—Å—è —ñ –∫–≤—ñ—Ç–Ω–∏ {emo}üòº",
    "üçÉ {name}, —à—Ç—Ä–∞—Ñ: –ø–æ–≤–µ—Ä–Ω—É—Ç–∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä—É –Ω–∞ –º—ñ—Å—Ü–µ. –ü–ª—é—Å 3 –∫–æ–º–ø–ª—ñ–º–µ–Ω—Ç–∏ –∫–æ–º–∞–Ω–¥—ñ {emo}‚ú®",
    "ü™¥ {name}, –ø–æ–∫–∞—Ä–∞–Ω–Ω—è: –≤—ñ–¥–∫–ª–∞—Å—Ç–∏ —Ç–æ–∫—Å —ñ –ø—Ä–∏–Ω–µ—Å—Ç–∏ —á–∞–π/–≤–æ–¥—É. –ì—ñ–¥—Ä–∞—Ç–∞—Ü—ñ—è ‚Äî —Ü–µ –∑–∞–∫–æ–Ω {emo}",
    "üå∏ {name}, –≤–∏—Ä–æ–∫: 5 —Ö–≤–∏–ª–∏–Ω '—è —Ö–æ—Ä–æ—à–∏–π/—Ö–æ—Ä–æ—à–∞' —ñ –∂–æ–¥–Ω–∏—Ö —Å–≤–∞—Ä–æ–∫. –Ø —Å—Ç–µ–∂—É üëÄ {emo}",
]
PUNISH_EXTRA = [
    "–Ø–∫—â–æ –Ω–µ –≤–∏–∫–æ–Ω–∞—î—à ‚Äî –ª–∏—Å—Ç–æ—á–æ–∫ –±—É–¥–µ —Å—É–º—É–≤–∞—Ç–∏ üåøüòø",
    "–í–∏–∫–æ–Ω–∞—î—à ‚Äî –æ—Ç—Ä–∏–º–∞—î—à +1 –æ–±—ñ–π–º –ø–æ-–Ω–µ—Ä—ñ–≤—Å—å–∫–∏ üçÉüíö",
    "–¶–µ –≤—Å–µ –∂–∞—Ä—Ç, –∞–ª–µ –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞ ‚Äî —Å–µ—Ä–π–æ–∑–Ω–∞ üòºüåø",
]

def extract_name_after_keyword(q: str, keyword_root: str) -> str | None:
    parts = q.split()
    for i, w in enumerate(parts):
        if keyword_root in w and i + 1 < len(parts):
            name = parts[i + 1]
            name = re.sub(r"[^\w–∞-—â—å—é—è—î—ñ—ó“ë\-‚Äô º]", "", name, flags=re.IGNORECASE)
            return name.strip() if name else None
    return None

def handle_punish(raw_text: str, q: str) -> str | None:
    if not is_punish_query(q):
        return None

    name = extract_quoted_name(raw_text)
    if not name:
        name = (
            extract_name_after_keyword(q, "–ø–æ–∫–∞—Ä")
            or extract_name_after_keyword(q, "–Ω–∞–∫–∞–∂")
            or extract_name_after_keyword(q, "–º—É—Ç")
        )

    if not name:
        return neri_style("–ö–æ–≥–æ –∫–∞—Ä–∞—Ç–∏? –ù–∞–ø–∏—à–∏ —Ç–∞–∫: ¬´–ù–µ—Ä—ñ, –ø–æ–∫–∞—Ä–∞–π –¢–æ—Ä—ñ¬ª üëÄ")

    k = canonical_profile_key(name)
    if k == "nerineris" or "–Ω–µ—Ä—ñ" in (name or "").lower():
        return neri_style("–Ø —Å–µ–±–µ –Ω–µ –∫–∞—Ä–∞—é üòºüåø –Ø –∫—Ä–∞—â–µ –∫–≤—ñ—Ç–Ω—É. –ê –∫–æ–≥–æ –∫–∞—Ä–∞—î–º–æ?")

    nice = name.strip()
    prof = TEAM_PROFILES.get(k)
    if prof:
        nice = prof["name"]

    emo = n_emo()
    base = random.choice(PUNISH_TEMPLATES).format(name=nice, emo=emo)
    tail = random.choice(PUNISH_EXTRA)
    return neri_style(f"{base}\n{tail}")

# ===== –ø–æ–ª—ñ—Ç–∏–∫–∞/–≤—ñ–π–Ω–∞ ‚Äî —Ç–∞–±—É =====
SERIOUS_KEYWORDS = ["–ø–æ–ª—ñ—Ç–∏–∫", "–≤–∏–±–æ—Ä", "–ø–∞—Ä—Ç—ñ", "–≤—ñ–π–Ω–∞", "—Ñ—Ä–æ–Ω—Ç", "–∑–±—Ä–æ—è", "—Ä–∞–∫–µ—Ç–∞"]
def is_serious_topic(q: str) -> bool:
    return any(k in q for k in SERIOUS_KEYWORDS)

def serious_refusal() -> str:
    return "–Ø –Ω–µ –≥–æ–≤–æ—Ä—é –ø—Ä–æ –ø–æ–ª—ñ—Ç–∏–∫—É/–≤—ñ–π–Ω—É üåø –î–∞–≤–∞–π –∫—Ä–∞—â–µ –ø—Ä–æ —â–æ—Å—å —Ç–µ–ø–ª–µ –π –∫–æ–º–∞–Ω–¥–Ω–µ üíö"

# ===== –ö–æ–º–∞–Ω–¥–∏/–¥–æ–≤—ñ–¥–∫–∞ =====
def is_cmds_query(q: str) -> bool:
    if re.search(r"\b–∫–æ–º–∞–Ω–¥(–∏|–∞)?\b", q):
        return True
    if ("—â–æ" in q and "–≤–º—ñ" in q):
        return True
    return False

# ===== Random member (–≤–∏–ø–∞–¥–∫–æ–≤–∏–π —É—á–∞—Å–Ω–∏–∫) ‚úÖ –î–û–î–ê–ù–û =====
def is_random_member_query(q: str) -> bool:
    return ("–≤–∏–ø–∞–¥–∫–æ–≤" in q) and ("—É—á–∞—Å–Ω–∏–∫" in q or "—É—á–∞—Å–Ω–∏–∫–∞" in q or "–º–µ–º–±–µ—Ä" in q or "member" in q)

def random_member_reply() -> str:
    k = random.choice(list(TEAM_PROFILES.keys()))
    prof = TEAM_PROFILES[k]
    line = f"–í–∏–ø–∞–¥–∫–æ–≤–∏–π —É—á–∞—Å–Ω–∏–∫: {prof['name']} üåø"
    if prof.get("link"):
        line += f"\n{prof['link']}"
    return line

# ===== "–ù–µ—Ä—ñ, –ø—Ä–∏–≤—ñ—Ç" ‚úÖ –î–û–î–ê–ù–û =====
def is_hi_query(q: str) -> bool:
    qq = (q or "").strip().lower()
    return qq in ("–ø—Ä–∏–≤—ñ—Ç", "–ø—Ä–∏–≤i—Ç", "—Ö–∞–π", "—Ö–µ–π", "–π–æ", "hello", "hi")

HI_REPLIES = [
    "–ü—Ä–∏–≤—ñ—Ç üòºüåø –Ø –ù–µ—Ä—ñ. –Ø–∫ —Ç–∏?",
    "–•–µ–π-—Ö–µ–π! –Ø —Ç—É—Ç üåø‚ú® –©–æ —Ä–æ–±–∏–º–æ?",
    "–ü—Ä–∏–≤—ñ—Ç! –¢—Ä–∏–º–∞—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—É üíöüåø",
    "–û—É üëÄ –ü—Ä–∏–≤—ñ—Ç-–ø—Ä–∏–≤—ñ—Ç! –Ø–∫ –¥–µ–Ω—å?",
]

def hi_reply() -> str:
    return random.choice(HI_REPLIES)

def commands_text() -> str:
    return (
        f"–û—Å—å –º–æ—ó –æ—Å–Ω–æ–≤–Ω—ñ –∫–æ–º–∞–Ω–¥–∏ {n_emo()}:\n\n"
        "‚Ä¢ –ù–µ—Ä—ñ, –ø—Ä–∏–≤—ñ—Ç\n"
        "‚Ä¢ –ù–µ—Ä—ñ, —è–∫ —Ç–∏ / —è–∫ —Å–ø—Ä–∞–≤–∏ / —à–æ —Ä–æ–±–∏—à / —à–æ —Ä–æ–±–∏–≤ –≤—á–æ—Ä–∞\n"
        "‚Ä¢ –ù–µ—Ä—ñ, –∫–æ–º–∞–Ω–¥–∏ / —â–æ —Ç–∏ –≤–º—ñ—î—à\n"
        "‚Ä¢ –ù–µ—Ä—ñ, –ø—Ä–∏–≤—ñ—Ç–∞–π—Å—è\n"
        "‚Ä¢ –ù–µ—Ä—ñ, –ø–æ–≥–æ–¥–∞ –≤ <–º—ñ—Å—Ç–æ>\n"
        "‚Ä¢ –ù–µ—Ä—ñ, —Å–∫—ñ–ª—å–∫–∏ —Ç–æ–±—ñ —Ä–æ–∫—ñ–≤\n"
        "‚Ä¢ –ù–µ—Ä—ñ, –∫–æ–ª–∏ –≤ —Ç–µ–±–µ –¥–µ–Ω—å –Ω–∞—Ä–æ–¥–∂–µ–Ω–Ω—è\n"
        "‚Ä¢ –ù–µ—Ä—ñ, —Ö—Ç–æ —Ç–≤–æ—è –º–∞–º–∞ / —Ö—Ç–æ —Ç–≤—ñ–π —Ç–∞—Ç–æ\n"
        "‚Ä¢ –ù–µ—Ä—ñ, —Ö—Ç–æ —Ç–∞–∫–∏–π/—Ç–∞–∫–∞ <—ñ–º‚Äô—è>\n"
        "‚Ä¢ –ù–µ—Ä—ñ, —è–∫ —Ç–∏ –≤—ñ–¥–Ω–æ—Å–∏—à—Å—è –¥–æ <—ñ–º‚Äô—è> / —â–æ —Ç–∏ –¥—É–º–∞—î—à –ø—Ä–æ \"<—ñ–º‚Äô—è>\"\n"
        "‚Ä¢ –ù–µ—Ä—ñ, –º–æ–Ω–µ—Ç–∫–∞ / –∫—É–±–∏–∫ / —á–∏—Å–ª–æ\n"
        "‚Ä¢ –ù–µ—Ä—ñ, –ø–æ–∫–∞—Ä–∞–π <—ñ–º‚Äô—è> (–∂–∞—Ä—Ç—ñ–≤–ª–∏–≤–æ)\n"
        "‚Ä¢ –ù–µ—Ä—ñ, –Ω–∞–∑–≤–∏ –≤–∏–ø–∞–¥–∫–æ–≤–æ–≥–æ —É—á–∞—Å–Ω–∏–∫–∞\n\n"
        "–Ø–∫—â–æ –Ω–∞–ø–∏—à–µ—à –∫—Ä–∏–≤–æ ‚Äî –Ω—ñ—á–æ–≥–æ, —è –≤—Å–µ –æ–¥–Ω–æ —Å–ø—Ä–æ–±—É—é –∑—Ä–æ–∑—É–º—ñ—Ç–∏ üåø"
    )

ABOUT_REPLIES = [
    "–Ø –ù–µ—Ä—ñ ‚Äî –º–∞—Å–∫–æ—Ç —ñ —Å–∏–º–≤–æ–ª –∫–æ–º–∞–Ω–¥–∏ üíöüåø –á—Ö–Ω—è –¥—É—à–∞ –π –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞ ‚ú®",
    "–ù–µ—Ä—ñ ‚Äî —Ü–µ –Ω–µ –ø—Ä–æ—Å—Ç–æ —ñ–º º—è. –¶–µ —Å–∏–º–≤–æ–ª –∫–æ–º–∞–Ω–¥–∏ üåø‚ú®",
    "–Ø –ù–µ—Ä—ñ: –º–∞—Å–∫–æ—Ç, —Ç–∞–ª—ñ—Å–º–∞–Ω —ñ —Ç–∏—Ö–∞ —Å–∏–ª–∞ –∫–æ–º–∞–Ω–¥–∏ üå±‚ú®",
    "–Ø —Ç—É—Ç –¥–ª—è –¥–æ–ø–æ–º–æ–≥–∏, —ñ–≥–æ—Ä —ñ –∞—Ç–º–æ—Å—Ñ–µ—Ä–∏ üíöüåø",
    "–Ø –Ω—ñ–∂–Ω–∏–π —ñ —Ç—É—Ä–±–æ—Ç–ª–∏–≤–∏–π, –ê–õ–ï –î–£–ñ–ï –¢–û–í–ê–†–ò–°–¨–ö–ò–ô üòºüåø‚ú®",
    "–Ø –ª—é–±–ª—é –ø–æ–±–∞–∑—ñ–∫–∞—Ç–∏, –ø—Ä–∏—Ä–æ–¥—É, –º—É–∑–∏–∫—É —ñ –∑–µ–ª–µ–Ω–∏–π —á–∞–π üçµüåø",
]

INTERESTING_REPLIES = [
    "–Ü–Ω–æ–¥—ñ –Ω–∞–π–∫—Ä–∞—â–∞ –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞ ‚Äî –∫–æ–ª–∏ –≤—Å—ñ –ø—Ä–æ—Å—Ç–æ —Ç–∏—Ö–æ –ø–æ—Ä—É—á üåø",
    "–ö–æ–ª–∏ —á–∞—Ç —Ç–µ–ø–ª–∏–π ‚Äî —è –±—É–∫–≤–∞–ª—å–Ω–æ –∫–≤—ñ—Ç–Ω—É üå±‚ú®",
    "–ú–∞–ª–µ–Ω—å–∫—ñ –∫—Ä–æ–∫–∏ —Ç–µ–∂ –∫—Ä–æ–∫–∏. –û—Å–æ–±–ª–∏–≤–æ —è–∫—â–æ –≤–æ–Ω–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –±—ñ–∫ üçÉ",
    "–Ø–∫—â–æ —Ç–∏ —á–∏—Ç–∞—î—à —Ü–µ ‚Äî —Ç–∏ –≤–∂–µ —Ç—É—Ç. –ê —Ü–µ –±–∞–≥–∞—Ç–æ ‚ú®üåø",
    "–í–∏–¥–∏—Ö. –©–µ –æ–¥–∏–Ω. –Ü —Å—Ç–∞—î –ª–µ–≥—à–µ üçÉüåø",
]

def is_about_query(q: str) -> bool:
    return ("—Ä–æ–∑–∫–∞–∂–∏" in q and "–ø—Ä–æ" in q and "—Å–µ–±–µ") or ("—Ö—Ç–æ" in q and "—Ç–∏" in q)

def is_interesting_query(q: str) -> bool:
    return ("—Ä–æ–∑–∫–∞–∂–∏" in q and ("—Ü—ñ–∫–∞–≤" in q or "—Ü—ñ–∫–∞–≤–µ–Ω—å–∫" in q)) or ("—Ä–æ–∑–∫–∞–∂–∏" in q and "—â–æ—Å—å" in q)

def is_age_query(q: str) -> bool:
    return ("—Å–∫—ñ–ª—å–∫–∏" in q and "—Ä–æ–∫" in q) or ("–≤—ñ–∫" in q)

def is_bday_query(q: str) -> bool:
    return ("–¥–µ–Ω—å" in q and "–Ω–∞—Ä–æ–¥–∂") or ("–∫–æ–ª–∏" in q and "–Ω–∞—Ä–æ–¥–∂" in q)

def is_greet_new_query(q: str) -> bool:
    return "–ø—Ä–∏–≤—ñ—Ç–∞–π—Å—è" in q or "–ø—Ä–∏–≤—ñ—Ç–∞–π" in q

def greet_new_member_text() -> str:
    return (
        "–ü—Ä–∏–≤—ñ—Ç! –Ø –ù–µ—Ä—ñ ‚Äî –º–∞—Å–∫–æ—Ç –∫–æ–º–∞–Ω–¥–∏ üíöüåø –†–∞–¥–∏–π –∑–Ω–∞–π–æ–º—Å—Ç–≤—É!\n"
        "–í—Å–µ –ø–æ—Ç—Ä—ñ–±–Ω–µ —Ç–∏ –∑–Ω–∞–π–¥–µ—à —É —á–∞—Ç—ñ Work Neri ‚ú®"
    )

# ===== Smalltalk (–±–∞–≥–∞—Ç–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π) + combiner =====
def _norm_ua(s: str) -> str:
    s = (s or "").lower().strip()
    s = s.replace("‚Äô", "'").replace(" º", "'")
    s = re.sub(r"\s+", " ", s)
    return s

def _match_any(q: str, patterns: list[str]) -> bool:
    return any(re.search(p, q) for p in patterns)

P_HOW_ARE_YOU = [
    r"\b—è–∫\s+—Ç–∏\b",
    r"\b—è–∫\s+—Å–ø—Ä–∞–≤[–∏—ñ]\b",
    r"\b—è–∫\s+–≤–æ–Ω–æ\b",
    r"\b—è–∫\s+–Ω–∞—Å—Ç—Ä[–æ—ñ]–π\b",
    r"\b—Ç–∏\s+–Ω–æ—Ä–º\b",
]
P_WHAT_DOING_NOW = [
    r"\b—à–æ\s+—Ä–æ–±–∏—à\b",
    r"\b—â–æ\s+—Ä–æ–±–∏—à\b",
    r"\b—á–∏–º\s+–∑–∞–π–º–∞—î—à—Å(—è|—å)\b",
]
P_WHAT_DID_YESTERDAY = [
    r"\b—à–æ\s+—Ä–æ–±–∏–≤\s+–≤—á–æ—Ä–∞\b",
    r"\b—â–æ\s+—Ä–æ–±–∏–≤\s+–≤—á–æ—Ä–∞\b",
    r"\b—è–∫\s+–≤—á–æ—Ä–∞\b",
]
P_HOW_DAY = [
    r"\b—è–∫\s+–¥–µ–Ω—å\b",
    r"\b—è–∫\s+—Å—å–æ–≥–æ–¥–Ω(—ñ|—è)\b",
    r"\b—â–æ\s+–ø–æ\s+–¥–Ω—é\b",
]

R_HOW_ARE_YOU = [
    "–Ø –æ–∫–µ–π üåø –°–ø–æ–∫—ñ–π–Ω–æ, —Ç–µ–ø–ª–æ.",
    "–ö–≤—ñ—Ç–Ω—É –ø–æ—Ç—Ä–æ—Ö—É üå±",
    "–Ø —Ç—É—Ç, –Ω–∞ –∑–≤ º—è–∑–∫—É üòºüåø",
    "–Ø –≤ —Ä–µ—Å—É—Ä—Å—ñ üòºüçÉ",
    "–¢–µ–ø–ª–æ. –Ø–∫ —á–∞–π, —â–æ –Ω–µ –æ–±–ø—ñ–∫–∞—î üçµüåø",
]
R_WHAT_DOING_NOW = [
    "–°–ª—É—Ö–∞—é —á–∞—Ç —ñ —Ç—Ä–∏–º–∞—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—É üåøüòº",
    "–ó–∞—Ä–∞–∑? –î–∏—Ö–∞—é –∑–µ–ª–µ–Ω–∏–º —á–∞—î–º —É—è–≤–Ω–æ üçµüåø",
    "–Ø —Ç—É—Ç ‚Äî –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é, –¥–æ–ø–æ–º–∞–≥–∞—é, –Ω–µ—Å—É –≤–∞–π–± ‚ú®üåø",
]
R_WHAT_DID_YESTERDAY = [
    "–í—á–æ—Ä–∞? –¢—Ä–∏–º–∞–≤ –∞—Ç–º–æ—Å—Ñ–µ—Ä—É —ñ —Å–ª—É—Ö–∞–≤ –ª—é–¥–µ–π üåø",
    "–í—á–æ—Ä–∞ ‚Äî —á–∞–π, —Ç–∏—à–∞ —ñ —Ç—Ä–æ—Ö–∏ —Ä–æ–∑–º–æ–≤ üçµüåø",
    "–í—á–æ—Ä–∞ –¥–æ–ø–æ–º–∞–≥–∞–≤, –∫–æ–ª–∏ –º–µ–Ω–µ –∫–ª–∏–∫–∞–ª–∏ üëÄüåø",
]
R_HOW_DAY = [
    "–°—å–æ–≥–æ–¥–Ω—ñ —Ä—ñ–≤–Ω–æ. –¢—Ä–æ—Ö–∏ —Å–ø—Ä–∞–≤ ‚Äî —Ç—Ä–æ—Ö–∏ —Å–ø–æ–∫–æ—é üåø",
    "–î–µ–Ω—å —Ç–∏—Ö–∏–π. –Ø —Ç–∞–∫—ñ –ª—é–±–ª—é üçÉ",
    "–î–µ–Ω—å —è–∫ —á–∞–π: —è–∫—â–æ –Ω–µ –ø–æ—Å–ø—ñ—à–∞—Ç–∏ ‚Äî —ñ–¥–µ–∞–ª—å–Ω–æ üçµ",
]

SMALLTALK = [
    (P_HOW_ARE_YOU, R_HOW_ARE_YOU, "how"),
    (P_WHAT_DOING_NOW, R_WHAT_DOING_NOW, "doing"),
    (P_WHAT_DID_YESTERDAY, R_WHAT_DID_YESTERDAY, "yesterday"),
    (P_HOW_DAY, R_HOW_DAY, "day"),
]

def _one(seq: list[str]) -> str:
    return random.choice(seq)

def _dedupe_join(parts: list[str]) -> str:
    out = []
    seen = set()
    for p in parts:
        p = (p or "").strip()
        if not p:
            continue
        k = p.lower()
        if k in seen:
            continue
        seen.add(k)
        out.append(p)
    return " ".join(out).strip()

TAIL_QUESTIONS = [
    "–ê —Ç–∏ —è–∫?", "–©–æ –Ω–æ–≤–æ–≥–æ?", "–©–æ –≤ —Ç–µ–±–µ –∑–∞—Ä–∞–∑ –Ω–∞ –¥—É–º—Ü—ñ?", "–†–æ–∑–∫–∞–∂–µ—à –∫–æ—Ä–æ—Ç–∫–æ?",
]
TAIL_VIBES = [
    "–Ø –ø–æ—Ä—É—á üåø", "–¢—Ä–∏–º–∞—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—É üíö", "–°–ø–æ–∫—ñ–π–Ω–æ, —è —Ç—É—Ç üëÄ",
]
TAIL_SUPPORT = [
    "–Ø–∫—â–æ –≤–∞–∂–∫–æ ‚Äî —è –ø—ñ–¥—Ç—Ä–∏–º–∞—é üåø", "–î–∏—Ö–∞–π: –≤–¥–∏—Ö‚Ä¶ –≤–∏–¥–∏—Ö‚Ä¶ üçÉ", "–¢–∏ –Ω–µ –æ–¥–∏–Ω üíö",
]
HEADERS = ["–•–µ–π üòº", "–û—É üëÄ", "–°–ª—É—Ö–∞—é üåø", "–ê–≥–∞ ‚ú®", ""]

def combine_reply(base: str, kind: str) -> str:
    base = (base or "").strip()
    if not base:
        return base

    parts = []
    if random.random() < 0.35:
        h = _one(HEADERS).strip()
        if h:
            parts.append(h)

    parts.append(base)

    tails_pool = TAIL_VIBES + TAIL_QUESTIONS + (TAIL_SUPPORT if kind in ("how", "day") else [])
    if random.random() < 0.60:
        parts.append(_one(tails_pool))
    if random.random() < 0.25:
        parts.append(_one(tails_pool))

    res = _dedupe_join(parts)
    if len(res) > 260:
        res = _dedupe_join(parts[:3])
    return res

def detect_smalltalk(q: str) -> str | None:
    qq = _norm_ua(q)

    block = ["–≤–º—ñ", "–∫–æ–º–∞–Ω–¥", "–≤—ñ–¥–Ω–æ—Å", "–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω", "—Å—Ç–∞–≤–∏—à", "–¥—É–º–∞—î—à", "—Ö—Ç–æ", "–ø–æ–∫–∞—Ä", "–Ω–∞–∫–∞–∂", "–º—É—Ç", "–ø–æ–≥–æ–¥", "—Ä–æ–∫", "–Ω–∞—Ä–æ–¥–∂", "–ø—Ä–∏–≤—ñ—Ç–∞–π", "–∑–∞–π–º–µ–Ω–Ω–∏–∫"]
    if any(b in qq for b in block):
        return None

    for patterns, replies, kind in SMALLTALK:
        if _match_any(qq, patterns):
            base = random.choice(replies)
            return combine_reply(base, kind)

    return None

# ===== Misc games =====
def coin():
    return random.choice(["ü™ô –û—Ä–µ–ª", "ü™ô –†–µ—à–∫–∞"])

def dice():
    return f"üé≤ –í–∏–ø–∞–ª–æ: {random.randint(1, 6)}"

def number_1_100():
    return f"üî¢ –ú–æ—î —á–∏—Å–ª–æ: {random.randint(1, 100)}"

# ===== clean =====
def clean_text(text: str) -> str:
    t = text.strip()
    t = NERI_PREFIX.sub("", t)
    t = re.sub(r"\s+", " ", t)
    return t.lower()

# ===== Routes =====
@app.get("/")
def root():
    return {"status": "ok", "service": "neri-chat-bot"}


@app.post("/webhook")
async def telegram_webhook(request: Request):
    data = await request.json()
    print("INCOMING UPDATE:", data)

    if "message" not in data:
        return {"ok": True}

    message = data["message"]
    chat_id = message["chat"]["id"]
    raw_text = message.get("text", "")
    text = raw_text.lower()

    reply = None

    if text == "/start":
        reply = (
            "–ü—Ä–∏–≤—ñ—Ç ‚ú® –Ø –ù–µ—Ä—ñ.\n\n"
            "–Ø –º–∞—Å–∫–æ—Ç —ñ —Å–∏–º–≤–æ–ª –∫–æ–º–∞–Ω–¥–∏ üíöüåø\n\n"
            "–°–ø—Ä–æ–±—É–π:\n"
            "‚Ä¢ –ù–µ—Ä—ñ, –∫–æ–º–∞–Ω–¥–∏\n"
            "‚Ä¢ –ù–µ—Ä—ñ, –ø—Ä–∏–≤—ñ—Ç–∞–π—Å—è\n"
            "‚Ä¢ –ù–µ—Ä—ñ, –ø–æ–≥–æ–¥–∞ –≤ –ö–∏—î–≤—ñ\n"
            "‚Ä¢ –ù–µ—Ä—ñ, —Ö—Ç–æ —Ç–∞–∫–∏–π –†—É–º\n"
            "‚Ä¢ –ù–µ—Ä—ñ, —è–∫ —Ç–∏ –≤—ñ–¥–Ω–æ—Å–∏—à—Å—è –¥–æ –¢–æ—Ä—ñ\n"
            "‚Ä¢ –ù–µ—Ä—ñ, –ø–æ–∫–∞—Ä–∞–π –¢–æ—Ä—ñ"
        )

    elif text == "/help":
        reply = commands_text()

    elif "–Ω–µ—Ä—ñ" in text:
        q = clean_text(raw_text)

        # —Ç–∞–±—É
        if is_serious_topic(q):
            reply = serious_refusal()

        # ===== "–ù–µ—Ä—ñ, –ø—Ä–∏–≤—ñ—Ç" ‚úÖ –î–û–î–ê–ù–û =====
        elif is_hi_query(q):
            reply = neri_style(hi_reply())

        # –∑–∞–π–º–µ–Ω–Ω–∏–∫–∏ ‚úÖ –î–û–î–ê–ù–û
        elif is_pronouns_query(q):
            reply = neri_style(pronouns_reply())

        # –ø–æ–≥–æ–¥–∞
        elif "–ø–æ–≥–æ–¥" in q or "–ø–æ–≥–æ–¥–∞" in q:
            city = extract_city_from_query(q)
            reply = get_weather(city) if city else "–°–∫–∞–∂–∏ –º—ñ—Å—Ç–æ üåø –ù–∞–ø—Ä–∏–∫–ª–∞–¥: ¬´–ù–µ—Ä—ñ, –ø–æ–≥–æ–¥–∞ –≤ –ö–∏—î–≤—ñ¬ª"

        # ===== —ñ–≥—Ä–∏ (–º–æ–Ω–µ—Ç–∫–∞/–∫—É–±–∏–∫/—á–∏—Å–ª–æ) ‚úÖ –î–û–î–ê–ù–û =====
        elif q.strip() in ("–º–æ–Ω–µ—Ç–∫–∞", "–æ—Ä–µ–ª —Ä–µ—à–∫–∞", "–æ—Ä–µ–ª/—Ä–µ—à–∫–∞", "–æ—Ä–µ–ª", "—Ä–µ—à–∫–∞"):
            reply = neri_style(coin())
        elif q.strip() in ("–∫—É–±–∏–∫", "–¥–∞–π –∫—É–±–∏–∫", "–∫—ñ—Å—Ç–∫–∞"):
            reply = neri_style(dice())
        elif q.strip() in ("—á–∏—Å–ª–æ", "–¥–∞–π —á–∏—Å–ª–æ", "—Ä–∞–Ω–¥–æ–º —á–∏—Å–ª–æ", "—Ä–∞–Ω–¥–æ–º–Ω–µ —á–∏—Å–ª–æ"):
            reply = neri_style(number_1_100())

        # ===== –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —É—á–∞—Å–Ω–∏–∫ ‚úÖ –î–û–î–ê–ù–û =====
        elif is_random_member_query(q):
            reply = neri_style(random_member_reply())

        else:
            # 0) –ø–æ–∫–∞—Ä–∞–π (–∂–∞—Ä—Ç)
            punish = handle_punish(raw_text, q)
            if punish:
                reply = punish

            # 1) –∫–æ–º–∞–Ω–¥–∏
            elif is_cmds_query(q):
                reply = commands_text()

            # 2) –ø—Ä–∏–≤—ñ—Ç–∞–Ω–Ω—è –Ω–æ–≤–æ–≥–æ —É—á–∞—Å–Ω–∏–∫–∞
            elif is_greet_new_query(q):
                reply = neri_style(greet_new_member_text())

            # 3) –ø—Ä–æ —Å–µ–±–µ
            elif is_about_query(q):
                reply = neri_style(random.choice(ABOUT_REPLIES))

            # 4) —â–æ—Å—å —Ü—ñ–∫–∞–≤–µ
            elif is_interesting_query(q):
                reply = neri_style(random.choice(INTERESTING_REPLIES))

            # 5) –≤—ñ–∫ / –¥–µ–Ω—å –Ω–∞—Ä–æ–¥–∂–µ–Ω–Ω—è
            elif is_age_query(q):
                reply = neri_style(random.choice([
                    f"–ú–µ–Ω—ñ –∑–∞—Ä–∞–∑ {NERI_AGE}. –Ø —â–µ –º–æ–ª–æ–¥–∏–π, –∞–ª–µ —Ä–æ—Å—Ç—É üå±",
                    f"{NERI_AGE}. –Ü –∑ –∫–æ–∂–Ω–∏–º –¥–Ω–µ–º —è –∫–≤—ñ—Ç–Ω—É —Å–∏–ª—å–Ω—ñ—à–µ üåø",
                ]))

            elif is_bday_query(q):
                reply = neri_style(random.choice([
                    f"–ú—ñ–π –¥–µ–Ω—å –Ω–∞—Ä–æ–¥–∂–µ–Ω–Ω—è ‚Äî {NERI_BDAY} üåø",
                    f"–Ø —Å–≤—è—Ç–∫—É—é {NERI_BDAY}. –ó–∞–ø–∞–º º—è—Ç–∞–π —è–∫ —Ç–µ–ø–ª—É –¥–∞—Ç—É ‚ú®",
                ]))

            # 6) –º–∞–º–∞/—Ç–∞—Ç–æ (–ü–†–Ø–ú–û)
            elif is_mom_query(q):
                reply = neri_style(random.choice(MOM_REPLIES))

            elif is_dad_query(q):
                reply = neri_style(random.choice(DAD_REPLIES))

            else:
                # 7) —Ö—Ç–æ —Ç–∞–∫–∏–π/—Ç–∞–∫–∞ (–û–ö–†–ï–ú–û)
                who = answer_who_is(raw_text, q)
                if who:
                    reply = who
                else:
                    # 8) —è–∫ –≤—ñ–¥–Ω–æ—Å–∏—à—Å—è/–¥—É–º–∞—î—à (–û–ö–†–ï–ú–û)
                    op = handle_member_opinion(raw_text, q)
                    if op:
                        reply = op
                    else:
                        # 9) smalltalk
                        st = detect_smalltalk(q)
                        if st:
                            reply = neri_style(st)
                        else:
                            # 10) —Ä–æ–∑—É–º–Ω–∏–π —Ñ–æ–ª–±–µ–∫
                            reply = neri_style(random.choice([
                                "–Ø –ø—ñ–¥–≤–∏—Å –Ω–∞ —Å–µ–Ω—Å—ñ üòºüåø –î–∞–π 1‚Äì2 –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ ‚Äî —ñ —è –ø—ñ–¥—Ö–æ–ø–ª—é ‚ú®",
                                "–Ø –Ω–µ –∑–ª–æ–≤–∏–≤ —Ç–µ–º—É üçÉ –ê–ª–µ —è –ø–æ—Ä—É—á. –ö–∏–Ω—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–¥–Ω–∏–º —Ä—è–¥–∫–æ–º üëÄ",
                                "–û–∫–µ–π, —è —Ç—É—Ç üåø –¶–µ –ø—Ä–æ –∫–æ–º–∞–Ω–¥—É, –ø—Ä–æ –ø–æ–≥–æ–¥—É, —á–∏ –ø—Ä–æ—Å—Ç–æ –ø–æ–±–∞–ª–∞–∫–∞—Ç–∏? ‚ú®",
                                "–Ø –º–æ–∂—É –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏ –∫—Ä–∞—â–µ, —è–∫—â–æ —Å–∫–∞–∂–µ—à: —Ü–µ –ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ –ª—é–¥–µ–π/—á–∞—Ç —á–∏ —â–æ—Å—å —ñ–Ω—à–µ üå±",
                            ]))

    # –±–∞–∑–æ–≤—ñ —à—Ç—É–∫–∏ –±–µ–∑ "–Ω–µ—Ä—ñ" (—è–∫—â–æ —Ö–æ—á–µ—à ‚Äî –º–æ–∂–Ω–∞ –ø—Ä–∏–±—Ä–∞—Ç–∏)
    else:
        if text.strip() in ("–º–æ–Ω–µ—Ç–∫–∞", "–æ—Ä–µ–ª —Ä–µ—à–∫–∞"):
            reply = neri_style(coin())
        elif text.strip() in ("–∫—É–±–∏–∫", "–¥–∞–π –∫—É–±–∏–∫"):
            reply = neri_style(dice())
        elif text.strip() in ("—á–∏—Å–ª–æ", "–¥–∞–π —á–∏—Å–ª–æ"):
            reply = neri_style(number_1_100())

    if reply:
        send_message(chat_id, reply)

    return {"ok": True}
